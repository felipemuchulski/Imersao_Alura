{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOXMkHd7lsRGMfIckyXHN8X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalando SDK do Google"
      ],
      "metadata": {
        "id": "A1UyppdhMFDC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwX9VE5nD-1r"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VtLaiaWCL8EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=\"AIzaSyAyI-SB3YDJjarnWWKTxcM5KBbFzgEElIQ\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "R2HZU-ntL8XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "HR_lvdn2PEtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "f43AQSFqPHDk",
        "outputId": "5da2a8a9-5eb5-43c5-875e-8b2b29c240b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5\n",
        "}"
      ],
      "metadata": {
        "id": "nMsxqfTcWtON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\"\n",
        "}"
      ],
      "metadata": {
        "id": "iPs9My7hXBQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo"
      ],
      "metadata": {
        "id": "M6UlHSfTYJg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\", generation_config=generation_config, safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "XEYAZGRjYN_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando o response"
      ],
      "metadata": {
        "id": "j0NYin1ZY-yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Vamos aprender assuntos sobre IA. Me dê sugestões\");\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "ugtu5ULNZBmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando o chatbot"
      ],
      "metadata": {
        "id": "P51boZvdZYa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[]);"
      ],
      "metadata": {
        "id": "yxE_QpcrZZ-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", response.text, \"\\n\")\n",
        "  prompt = input(\"Esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "MewGPjvhaHlN",
        "outputId": "549219a8-cd9d-4308-f0e4-e078c56a86a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: Como passar café em uma cafeteira italiana?\n",
            "Resposta:  **Materiais necessários:**\n",
            "\n",
            "* Cafeteira italiana (moka)\n",
            "* Café moído (moagem média)\n",
            "* Água\n",
            "\n",
            "**Instruções:**\n",
            "\n",
            "1. **Desmonte a cafeteira:** Desaparafuse a parte superior da cafeteira e remova o funil e o filtro.\n",
            "2. **Encha o reservatório inferior com água:** Encha o reservatório inferior com água fria até a válvula de segurança.\n",
            "3. **Adicione café moído ao funil:** Encha o funil com café moído até a borda. Não pressione o café.\n",
            "4. **Recoloque o filtro e o funil:** Coloque o filtro sobre o reservatório inferior e aparafuse o funil por cima.\n",
            "5. **Aperte a cafeteira:** Aparafuse a parte superior da cafeteira na parte inferior até que esteja bem apertada.\n",
            "6. **Coloque no fogo:** Coloque a cafeteira em fogo médio ou baixo.\n",
            "7. **Observe a água:** À medida que a água aquece, ela subirá pelo funil e passará pelo café moído.\n",
            "8. **Quando o café começar a borbulhar:** Quando o café começar a borbulhar e sair do bico, retire a cafeteira do fogo.\n",
            "9. **Sirva:** Despeje o café imediatamente em xícaras pré-aquecidas.\n",
            "\n",
            "**Dicas:**\n",
            "\n",
            "* Use água filtrada ou de nascente para obter o melhor sabor.\n",
            "* Experimente diferentes tipos de café moído para encontrar o seu favorito.\n",
            "* Não encha demais o funil com café, pois isso pode obstruir o filtro.\n",
            "* Não deixe a cafeteira no fogo por muito tempo, pois isso pode queimar o café.\n",
            "* Limpe a cafeteira regularmente para evitar o acúmulo de resíduos de café. \n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat"
      ],
      "metadata": {
        "id": "P1AO3LGgquEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat.history"
      ],
      "metadata": {
        "id": "efXuIVj4qvsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimindo histórico de visualização:"
      ],
      "metadata": {
        "id": "2YdzFX2Mmyrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "\n",
        "#Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-----------------------------------')\n"
      ],
      "metadata": {
        "id": "dM9hr-EWm2xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "Dx8WTqubF4vl"
      }
    }
  ]
}